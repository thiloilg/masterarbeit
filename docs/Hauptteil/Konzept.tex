\chapter{Konzept}
\label{chap:konzept}

Zur Erstellung des Konzepts gilt es mehrere Aspekte im Voraus genauer zu betrachten.
Dabei wird als erstes in \Cref{sec:weristmeinezielgruppe} die Zielgruppe der Softwarelösung analysiert. Daraufhin
wird in \Cref{sec:anforderungsanalyse} die Anforderungsanalyse der vier Aspekte; Gestaltung, Funktionalität,
Flexibilität und Codebasis behandelt. Nach der Anforderungsanalyse gilt es
in \Cref{sec:auswertungvorhandenersoftwareloesungen} die aktuelle Lage
des Marktes zu analysieren. Tools im Bereich der Geschäftsanalytik gibt es viele. \cite{WikiBISoftware}
Was zeichnet diese Softwarelösungen aus? Mit welchen Merkmalen kann man sich von vorhandenen Lösungen
bewusst unterscheiden? In \Cref{sec:progressivewebapp} und \ref{sec:microservices} beschäftigt
sich die Arbeit mit der Analyse zweier für die Softwarelösung relevanter Technologien.
Bei der ersten Technologie handelt es sich um eine Progressive Web App. Hier gilt es folgende
Fragen zu beantworten: Was ist eine Progressive Web App und macht diese 
im Kontext der Benutzeranforderungen Sinn? Was sind Vor- und Nachteile gegenüber nativer Apps?
Wie sieht es mit der Unterstützung der Plattformen aus? Als zweites wird ein für die
Serverinfrastruktur relevantes Architekturmuster als Lösungsansatz diskutiert. Hierbei
stellen sich folgende Leitfragen: Was versteht man unter Microservices? Was ist der Kompromiss,
den man eingeht, wenn man sich für eine Microservice-Infrastruktur entscheidet?

Sind all diese Fragen beantwortet, kann ein Grundkonzept der Gesamtanwendung entwickelt werden.
Hierbei werden in \Cref{sec:zielsetzung} die Ziele für die Softwarelösung gesetzt. In \Cref{sec:entwurf}
werden daraufhin Entwürfe sowohl von der Benutzeroberfläche als auch von der Infrastruktur vorgestellt.
Weitere Designentscheidungen werden in den folgenden Kapiteln debattiert.

\section{Continuous Delivery}
\label{sec:continuousdelivery}
Continuous Delivery (CD ist das Verfahren, Software in einem stetigen Zyklus auszuliefern.
Neue Technologien, wie die Containervirtualiserungssoftware Docker,
die im März 2013 von dotCloud ins Leben gerufen wurde \cite{DockerAbout2014}, vereinfachen
den stetigen Softwareauslieferungsprozess enorm. So kann man in einem automatisierten
Auslieferungsprozess, Images bauen, diese testen und selbige nach erfolgreichem
Bestehen der Tests in der Produktion verwenden. Eberhard Wolff schreibt über das Ziel von Docker in
seinem Buch "Continuous Delivery" folgendes: "Das Ziel von Docker ist es, Container für die
Distribution von Software zu nutzen. Im Vergleich zu normalen Prozessen trennen Linux-Container
einzelne Anwendungen viel besser voneinander, wenn es darum geht, die Software auf einem anderen
System zu installieren. Docker bietet ein Repository für Images an, so dass eine Vielzahl
von Servern mit identischen Images betrieben werden können."\cite[S. 56]{ContinuousDeliveryWolff}
Somit kann sichergestellt werden, dass die Software und deren Umgebung in der Testphase
sowie in Produktion die selbe ist. Immer mehr Anbieter stellen CI-Werkzeuge zur Verfügung,
die es ermöglichen eine CI/CD-Pipeline anhand von Konfigurationsdateien aufzuziehen. So bieten nun
neben Travis CI, CircleCI und Jenkins auch Versionsverwaltungshosts wie Github und
Gitlab CI-Werkzeuge zur Verfügung.\footnote{Github bietet seit 13. November 2019 eigene CI/CD-Werkzeuge an \cite{GithubCIToolsHeise}}
Vorteile eines CD-Ansatzes sind schnelle Feature-Auslieferung und somit schnellere Resonanz der Benutzer auf die Features,
Robustheit der Software durch stetiges Ausführen automatisierter Tests in der Pipeline, einfaches Zurückrollen
der Version der Anwendung in Produktion sowie einfaches Reproduzieren von Fehlern. Ein Nachteil eines CI/CD-Ansatzes ist
der große Aufwand des initialen Aufbaus der automatisierten Prozesse. Bei komplexen Änderungen des Systems müssen zudem
große Teile des automatisierten Prozesses angepasst werden.

\section{Monorepo und Submodules}
\label{sec:monorepoundsubmodules}
In diesem Abschnitt geht es um die Aufteilung des Programmcodes in Repositories. Für die Versionsverwaltung
wird Git verwendet. Die Arbeit entscheidet sich dazu, die einzelnen Microservices in einer Monorepo unterzubringen.
Unter Monorepo versteht man die Strategie, den Programmcode aus mehreren Anwendungen, Services, Bibliotheken und Frameworks
in einer Repository unterzubringen.\cite{MonorepoTrunkBasedDevelopment} Diese Strategie verringert nicht nur den Aufwand
des Aufsetzens mehrerer Repositories, sondern gibt den Entwicklern auch einen besseren Überblick über die einzelnen
Projekte. Gerade im Fall von Microservices hat dieser Ansatz den Vorteil, dass man Änderungen in mehreren Services,
die miteinander verkoppelt sind, in einem Commit in die Versionsverwaltung einchecken kann. Dies kann verbindlich sein,
wenn Tests der Pipeline auf bestimmte Versionen der unterschiedlichen Services angewiesen sind. Verändert man beispielsweise
eine API eines Services, kann man gleichzeitig das Frontend anpassen. Die Diagramme eines Dashboards sollen allerdings
auch extern entwickelbar sein. Um dies zu ermöglichen, verwendet die Arbeit Git-Submodules.\cite{GitsubmodulesGitSCM} Mithilfe dieser Submodules
kann man andere Repositories in ein Repository integrieren. Somit können externe Entwickler das Repository des
Submodules gabeln\footnote{Unter "gabeln" oder auch "forken" versteht man das Erstellen einer eigenen Kopie eines Repositories, mit der unabhängig von der Versionierung der gegabelten Repository entwickelt werden kann.},
um in ihrem eigenen Repository Diagramme für die Anwendung zu entwickeln.

\section{Kompromiss}
\label{sec:kompromiss}
In den vorherigen Abschnitten wurden die Anforderungen ermittelt, verwandte Softwarelösungen
studiert sowie zwei relevante Technologien genauer betrachtet. In der Zielsetzung soll nun
anhand der daraus resultierenden Erkenntnisse ein klares, aussagekräftiges Ziel definiert werden.
Dabei müssen Kompromisse eingegangen werden. Aufgabe der Zielsetzung ist es unter anderem,
die Gewichtung auf die zuvor erörterten Anforderungen zu verteilen. In \Cref{sec:entwurf}
wird daraufhin ein grober Entwurf konzipiert. Am Ende der Arbeit wird anhand der Zielsetzung
und der Auswertung ein Fazit gezogen.

Was ist das Ziel dieser Arbeit? Aus rein funktionaler Sicht ist das Ziel dieser Arbeit
folgendes: Eine Webanwendung zu entwickeln, die Daten aus einer API ausließt,
diese verarbeitet und in einem Dashboard veranschaulicht. Nutzer können sich
in der Webanwendung anmelden, externe API-Aufrufe als Datenquellen bestimmen,
die empfangenen Daten verarbeiten, ein Dashboard mit Diagrammen per Drag and Drop erstellen
und den im Dashboard enthaltenen Diagrammen Datenquellen zuweisen. Die erstellten
Dashboards können die Nutzer dann verwenden, um ihre aktuell über die externen 
API-Aufrufe zur Verfügung gestellten Daten auszuwerten. Die Funktionalität
ist das Herz der Anwendung und hat somit aus funktionaler Sicht höchste Priorität.
Aus wissenschaftlicher Sicht ist das Ziel dieser Arbeit die zuvor genannte
Funktionalität mithilfe einer langlebigen, gutdurchdachten, benutzerfreundlichen,
robusten sowie performanten Softwarearchitektur zu verwirklichen. Auf wissenschaftlicher
Ebene spielt die Auseinandersetzung mit der Erforschung und Findung einer möglichst perfekten
Lösung für die Verwirklichung eines solchen Systems, eine, der Implementierung selbst,
übergeordneten Rolle. Dabei stellen sich folgende Fragen: Wie kann ein möglichst agiler
Prozess der Erstellung eines Dashboards aussehen? Wie muss die Logik innerhalb des Systems
getrennt werden? Wie kann der Datenfluss optimiert werden? Wie können Qualitätsmerkmale
gesichert werden? All diese und noch viele weitere Fragen gilt es zu beantworten.

Wie sieht es mit der Gewichtung der in der Anforderungsanalyse in \Cref{sec:anforderungsanalyse}
ausgearbeiteten Anforderungen an die Gestaltung, Funktionalität, Flexibilität und Codebasis aus?
Am einfachsten kann man diese Frage beantworten, in dem man sich klarmacht, was keinen wissenschaftlichen
Mehrwert hätte. Eine API im Frontend aufzurufen, die erhaltenen Daten hartkodiert zu verarbeiten und
in einer möglichst größen Anzahl an hartkodierten Diagrammen anzuzeigen. Das würde eventuell auf den
ersten Blick gut aussehen, hat aber mit der Entwicklung einer soliden Softwarelösung nichts zu tun.
Um eine solide Softwarelösung bewerkstelligen zu können, benötigt es eines soliden Softwaredesigns.
Ein solches Design soll das primäre Ziel dieser Arbeit sein. Robert C. Martin sagt zur Qualität eines
solchen Designs folgendes:
"Die Qualität des Designs bemisst sich schlicht und ergreifend an dem Ausmaß des Aufwands, der
erforderlich ist, um den Bedürfnissen der Kunden gerecht zu werden. Bedarf es hierfür eines
geringen Aufwands und bleibt dies auch während der gesamten Lebenszeit des Systems so,
dann handelt es sich um ein gutes Design — steigt der Aufwand mit jedem neuen Release,
taugt das Design nichts. So einfach ist das."\cite[S. 30]{RobertC.Martin2018} Was heißt
das aber nun für die Gewichtung der in der Anforderungsanalyse erarbeiteten Anforderungen?
Ziel dieser Arbeit ist es bei der Entwicklung der Softwarelösung mehr Wert auf die Flexibilität
der Software als auf den Funktionsumfang einzelner Merkmale zu legen. In unserem
vorherigen Beispiel heißt das konkret: Richtig ist es, eine Software zu entwickeln, die zwar erst ein Diagramm
implementiert hat, wo aber der Vorgang, ein weiteres Diagramm hinzuzufügen, vereinfacht wurde.
Falsch ist es, eine Software zu entwickeln, wo zwar bereits hunderte Diagramme implementiert sind,
der Vorgang, ein neues hinzuzufügen, allerdings immer komplexer wird.

\section{Trennung der Logik}
\label{sec:trennungderlogik}
Die Benutzerverwaltung muss klar von der Zulieferung der Daten getrennt werden.
In der Zulieferung müssen die Daten verarbeitet und für die Frontendanwendung
vorbereitet werden. Dieser Rechenaufwand ist nicht mit dem der Benutzerverwaltung
zu vergleichen. So kann bei der Datenzulieferung die Menge der über die Netzwerkverbindung
gesendeten Daten stark variieren. Dies ist in der Benutzerverwaltung nicht der Fall. 
Hier werden maximal zehn Ressourcen wie Benutzer, Datenquellen, Dashboards oder Charts
auf einer Seite angezeigt. Die Nutzlast verhält sich somit statisch. Für dieses Verhalten
eignet sich eine REST-API über HTTP. Die Orientierung an den Entitäten spiegelt sich in der Navigation
im Frontend wider. Die Zulieferung der auszuwertenden Daten muss in Echtzeit erfolgen.
Hier ist eine bidirektionale Kommunikation zwischen Server und Client von Vorteil.
Für solch eine Kommunikation eignet sich eine WebSocket-Verbindung. Nach dem über HTTP erfolgten
Handshake rüstet sich die Verbindung auf das WebSocket-Protokoll auf. Die WebSocket-Verbindung
findet direkt auf der TCP-Schicht statt, wodurch man den HTTP-Mehraufwand umgeht.\footnote{Dieser Mehraufwand ist beispielsweise der bei jeder Anfrage mitgeschickte HTTP-Header}
Eine WebSocket-Verbindung ist allerdings serverseitig sehr teuer, da die Verbindung während der Nutzung
der Webanwendung kontinuierlich aufrechterhalten werden muss.\footnote{Man könnte natürlich die Verbindung immer wieder neu öffnen, der dafür nötige Handshake ist allerdings kostenaufwändiger als eine einfache HTTP-Abfrage.} 
Es ist also essentiell, dass der Service, der sich um die Zulieferung der auszuwertenden Daten kümmert,
getrennt von dem, der die Benutzerverwaltung bereitstellt, skaliert werden kann.

Es sollte keine direkte Kommunikation zwischen dem Service der Benutzerverwaltung und dem
Service der Datenzulieferung bestehen (siehe Abbildung \ref{figure:trennungderlogic}).
Jeder Service besitzt sein eigenen Cache und seine eigene Datenbank. Somit sind
die Services komplett unabhängig entwickel-, ausliefer- und skalierbar. Die Abhängigkeit der einzelnen
Services mit dem Frontend ist natürlich immernoch gegen. Diese Abhängigkeit muss man
allerdings in Kauf nehmen.

Der Benutzerverwaltungsdienst sowie der Datenzulieferungsdienst sind als einzelne Microservices
im Backend zu verstehen. Ziel ist es, diese Services in Zukunft durch weitere Services zu ergängen.

\begin{figure}
    \begin{center}
    \includegraphics[scale=0.2]{img/abbildungen/TrennungDerLogic}
    \end{center}
    \caption{Trennung der Logic}
    \label{figure:trennungderlogic}
\end{figure}

Die Arbeit verfolgt auch für das Frontend einen Microservice-Ansatz. Man spricht hier von einem
Microfrontend. Michael Geers schreibt dazu in einem Artikel auf Digital Pioneers folgendes:
"Der Ansatz, der sich jetzt förmlich aufdrängt, ist die Umsetzung der Microservice-Idee
auch im Frontend. Anstatt einer ­großen Single-Page-Applikation baut man mehrere unabhängige
Teilapplikationen, die miteinander kommunizieren. Diese sind dann deutlich einfacher zu verstehen.
Der Einsatz einer neuen Technologie lässt sich in einem kleineren Rahmen testen."\cite{MicrofrontendT3N}
Dabei sollen die Diagramme eines Dashboards als einzelne Services ausgelagert werden (wie in Abbildung \ref{figure:trennungderlogic} dargetstellt).
Die Diagramme können so einzeln entwickelt und ausgeliefert werden. Aufgrund der
gleichen Machenschaft der Schnittstellen der Diagramme, kann man diese Art des Code-Splittings auch als
einen Plugin-Ansatz ansehen. Die Diagramme sollen über die In-Memory-Datenbank
Redis zur Verfügung gestellt werden. Die PWA selbst soll vorerst über einen
Nginx Webserver und später über ein CDN ausgeliefert werden. Die Diagramme werden mithilfe
von Dynamic Imports\footnote{Dynamic Imports gibt es seit ES6 (ECMAScript 2015)\cite{DynamicImportsV8}}
während der Laufzeit agil nachgeladen. Da immer nur die verwendeten Diagramme aus der In-Memory-Datenbank
geladen werden, kann die Webanwendung eine nahezu unendliche Auswahl an möglichen Diagrammen zur Visualisierung
der Daten bereitstellen.

\section{Diagrammanordnungsverfahren}
\label{sec:diagrammanordnungsverfahren}
Das Diagrammanordnungsverfahren beschreibt den Prozess, einzelne Diagramme in einem Dashboard anzuordnen.
Um das Verfahren zu vereinfachen, ist ein automatisches Anordnen der Diagramme diagonal sowie vertikal vorgesehen.
Die Anordnung der einzelnen Diagramme soll mithilfe der FlexBox Technologie implementiert werden.
\footnote{CSS Flexible Box Layout, bekannt als FlexBox, ist ein standardisiertes Anordnungsmuster, das von allen gängigen Browsern unterstützt wird.\cite{CanIUseFlexBox}}
Im mobilen Format sollen die einzelnen Diagramme untereinander aufgelistet werden. 

\begin{figure}
    \begin{center}
    \includegraphics[scale=0.2]{img/abbildungen/DiagrammanordnungsverfahrenMitLegende}
    \end{center}
    \caption{Diagrammanordnunsverfahren}
    \label{figure:diagrammanordnungabbildung}
\end{figure}

Die Diagramme sollen nach und nach per Drag and Drop in das Dashboard integriert werden. Dieses Verfahren
wird in Abbildung \ref{figure:diagrammanordnungabbildung} dargestellt. \(a\) beschreibt den
initialen Zustand eines leeren Dashboards. Hier kann man durch Drag and Drop das erste Diagramm dem Dashboard
zuordnen. \(b\) beschreibt den Zustand des Dashboards mit genau einem enthaltenen Diagramm. Hier kann man das
neue Diagramm in alle Richtungen einfügen. Dabei Teilt das bestehende Diagram den Platz mit dem neuen gleichmäßig
auf. Bei der mittigen Positionierung wird das vorhandene Diagramm durch das neue ersetzt. \(c\) und \(d\)
beschreiben den Zustand, bei dem sich mehr als ein Diagramm im Dashboard befindet. Wenn man im Zustand \(b\)
ein Diagramm oberhalb oder unterhalb einfügt, bilden die beiden Diagramme eine Spalte. Beide dieser Diagramme
beinhalten nun den Zustand \(c\). Additional zu den möglichkeiten von Zustand \(b\), kann hier ein Diagramm
auch dazwischen gefügt werden. Es teilt sich dann den Platz mit den anderen Diagrammen in der Spalte.
Fügt man bei Zustand \(b\) ein Diagramm links oder rechts ein, bilden die beiden Diagramme eine Reihe.
Beide dieser Diagramme befinden sich nun in Zustand \(d\). Additional zu Zustand \(b\) können hier nun
auch neue Diagramme in der gleichen Reihe positioniert werden. Diese Reihen und Spalten können sich
immer weiter verschachteln. Somit kann der Benutzer mit einem ziemlich einfachen, intuitiven Verfahren
das Dashboard mit Diagrammen füllen. Durch einen Button in der Ecke rechts oben im Diagramm-Fenster
können diese auch wieder gelöscht werden. Dabei verhalten sich die zuvor beschriebenen Verfahren einfach rückläufig.
Die Anordnung der Diagramme wird als Baumstruktur im JSON-Format in der Datenbank persistiert.

\section{Qualitätssicherung}
\label{sec:qualitaetssicherung}

\section{Testgetriebene Entwicklung}
% Wie sieht richtige testgetriebene entwicklung aus?
% Wann machen Tests Sinn, wann machen welche tests sinn?
% seeds. besähen der Daten etc.

\subsection{Schnittstellentests}
% Integrationstests mit Fokus auf Schnittstellentests
% Teil der Integrationstests

%% VON SEEDS DATABASE POPULATION
%% Database seeding admin account etc.
%% Probleme with extra route to initialize administration account!!!
%% Problem initializing with trivial password since a lot of provider forget to update
%% also known as Populating a Database
%% Problem Typeorm auto sync
%% necessary also for as fixtures, a basic setup for running tests

\subsection{Komponententests}
% react hook tests

\subsection{End-to-End-Tests}
% Cypress

\subsection{Lighthouse Tests}
% Google Lighthouse tests sinnvoll einsetzen um die PWA zu vervollständigen
% performance

\section{Automatisierung von Entwicklungsprozessen}
\subsection{Git Hooks, Eslint und Prettier}
% Prettier
% Eslint
\subsection{Multistage Build}
\subsection{Aufsetzen des Projekts}
% one command 
\subsection{Nodemon und Reflex}
% docker-compose mapping automatischer neustart der services

\section{Refactoring}
% Konstantes Refactoring, über die Zeit kann sich die
% ideale art der Projektstruktur, der Software architektur,
% des System designs, der auslastung der Services angleichen
% Daher ist eine kontinuierliche Veränderung der gesamten
% Infrastruktur erforderlich
% Projektstruktur auch hier behandeln
% Domain Driven Design

\section{Dokumentation}
\subsection{Für externe Entwickler}
% Swagger swagger-jsdoc etc open API 3.0

\subsection{Für interne Entwickler}
% clean simple code


\section{Kompontentendesign}
\label{sec:komponentendesign}


%%% IN diesem Kapitel werden für die einzelnen services der Tech stack geklärt etc.!!!

\section{Resource Management API}
\label{sec:resourcemanagementapi}

\subsection{Authentifizierungsverfahren}
\label{subsec:authentifizierungsverfahren}
% JWT vs Session
% Whitelist statt Blacklist

\section{Data Delivery API}
\label{sec:datadeliveryapi}


\section{Schnittstellengestaltung}
\label{sec:schnittstellengestaltung}
