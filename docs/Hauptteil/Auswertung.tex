\chapter{Auswertung}
\label{chap:auswertung}
In diesem Kapitel soll die Software anhand von für die Softwareentwicklung relevanten Qualitätsmerkmalen
ausgewertet werden. Laut Peter Liggesmeyer, dem Autor des Buches "Software-Qualität", sind diese
Korrektheit, Vollständigkeit, Sicherheit, Zuverlässigkeit, Verfügbarkeit und Robustheit \cite[S. 5]{SoftwareQualitaet}.

\section{Korrektheit}
\label{sec:korrektheit}
Um die Korrektheit der Gesamtanwendung beurteilen zu können, muss das in der Anforderungsanalyse erwartete
Verhalten mit dem Verhalten des Istzustands verglichen werden. In der Anforderungsanalyse
in \Cref{chap:anforderungsanalyse} wurden hauptsächlich Funktionalitäten und weniger deren 
Verhalten behandelt. Da das Verhalten der Software vor der Entwicklung des Konzepts nicht klar definiert wurde,
ist es schwer, die Korrektheit der Anwendung zu beurteilen. Die in der Konzeptphase erarbeiteten Verfahren
wurden, wie in dem Konzept entworfen, auch in der Software schlussendlich umgesetzt. So wurden für
das Diagrammanordnungsverfahren ein vielfaches an Modultests implementiert, um das gewollte Verhalten auch in
der Anwendung sicherzustellen. Das in den Konzepten erarbeitete Verhalten weicht nicht von dem der späteren
Umsetzung ab. Dies ist auch für die Schritte des Datenstroms und den angeforderten Funktionalitäten der Fall.
Daraus ist zu schlussfolgern, dass die Software korrekt ist.

\section{Vollständigkeit}
\label{sec:vollstaendigkeit}
Die Vollständigkeit der Software lässt sich einfach beurteilen. Hierfür müssen nur die in der Anforderungsanalyse
erarbeiteten Funktionalitäten mit denen des Istzustands verglichen werden. Die wichtigsten Funktionalitäten
wurden alle umgesetzt. So kann die Gesamtanwendung Daten beschaffen, verarbeiten, Diagrammen zuweisen und darstellen.
Da sich die Arbeit bei der Konzeption und Implementierung der Software auf die Qualitätsmerkmale Sicherheit,
Zuverlässigkeit, Verfügbarkeit und Robustheit fokussiert hat, konnten nicht alle angeforderten Implementierungsdetails
erfüllt werden. Die Authentifizierung, Rechteverwaltung, Sprachauswahl, Suche und Echtzeitübertragung der Daten wurden
voll funktionsfähig umgesetzt. Nicht oder nur bedingt wurde die Offline-Funktionalität, die Benachrichtigung
des Benutzers bei Übertretung eines vordefinierten Schwellwerts sowie die Filterung der Daten in den Diagrammen umgesetzt.
Die Offline-Funktionalität ist aktuell nur für statische Elemente der Anwendung gegeben. Die über das WebSocket-Protokoll
übertragenen Daten werden aktuell nicht in der progressiven Webanwendung gespeichert. Dies ist aus technischer
Sicht auch nur bedingt möglich, da das Speichervolumen von vom Browser bereitgestellten Speichermöglichkeiten
je nach Browser variiert und gerade auf mobilen Endgeräten oftmals sehr gering ausfällt \cite{HTML5RocksStorage}.
Die Benachrichtigung der Benutzer bei dem Übertreten eines vordefinierten Schwellwerts wurde noch nicht umgesetzt.
Die Funktionalität ist für die Zukunft geplant. Die Filterung der Daten ist bedingt möglich. So kann 
man, mithilfe Abfragesprache JMESPath, Daten anhand diverser Kriterien filtern.
Des Weiteren bietet die Visualisierungsbibliothek Chart.js bedingt Filtermöglichkeiten an. Ein selektives Filtern,
beispielsweise anhand einer Zeitspanne, ist nach aktuellem Stand innerhalb der Diagramme noch nicht umgesetzt worden.
Die Diagramme wurden so konzipiert, dass das Hinzufügen einer Filterfunktion
kein Problem darstellen sollte.

\section{Sicherheit}
\label{sec:sicherheit}
Auf die Sicherheit der Gesamtanwendung wurde besonders geachtet. So
wurde, wie bereits in der Implementierung erläutert, neben
der JWT\hyp{}Authentisierung auch eine Zwei\hyp{}Faktor\hyp{}Authentisierung
implementiert. Außerdem wurden in dem "Resource Management Service"
der Ein- und Ausgangsverkehr in beide Richtungen mithilfe des Koa Joi Routers validiert. Die Anwendung sowie die dafür benötigten
Daten werden über HTTPS als auch WSS ausgeliefert. \mbox{Nichtsdestotrotz} beinhaltet die Gesamtanwendung
noch Schwachstellen, die es zu eliminieren gilt. Für das Authentifizierungsverfahren wird, wie in der Implementierung beschrieben,
ein JWT in den HTTP-Header gesetzt. Bei der WebSocket-Verbindung findet die Authentifizierung beim Handshake des
Verbindungsaufbaus statt. Die Verbindung wird somit nicht getrennt, wenn der Token abläuft. Die Frontend-Anwendung
schließt allerdings bei der Abmeldung eines Benutzers die WebSocket-Verbindung automatisch. Es wäre allerdings dennoch möglich,
dass bei einer erfolgreichen XSS\hyp{}Attacke die WebSocket\hyp{}Verbindung aufrechterhalten wird, um so Daten zu stehlen.

Die Verwendung von \code{dangerouslySetInnerHTML} ist ein weiterer Sachverhalt. Zur Verarbeitung
der Daten wird ein Syntax-Highlighter verwendet, um die Ein- und
Ausgangsdaten in Form des JSON-Schemas anzuzeigen.
Da dieser allerdings in React zu langsam war, wurde er
in nativem JavaScript implementiert und mithilfe des 
\code{dangerouslySetInnerHTML} Feldes in den React Code eingebunden. Gesetzt den Fall, dass die externe,
als Datenquelle verwendete API korrupte Daten ausliefert, könnten diese als Einstiegspunkt für eine XSS-Attacke verwendet werden.
Wenn man allerdings die angezeigten Zeilen der Ein- und Ausgangsdaten auf eine moderate Anzahl begrenzt, kann ein
in React geschriebener Syntax-Highlighter verwendet und somit die Schwachstelle umgangen werden. Für die Zukunft ist geplant,
das JSON-Schema nie ganz anzuzeigen. Ziel ist es, das Schema stückchenweise aufzuklappen.

Der letzte Sicherheitsaspekt, den es anzusprechen gilt, ist die SSH-Verbindung aus der Pipeline heraus zu den Produktionsservern.
Hat ein Eindringling Zugriff auf die Pipeline, hat er gleichzeitig Zugriff auf alle Produktionsserver. 
Um dies zu vermeiden, können WebHooks verwendet werden. So kann die Pipeline eine Nachricht via WebHook an
den Produktionsserver senden, der daraufhin die Docker-Images mit denen aus der Docker Registry austauscht.

\section{Zuverlässigkeit}
\label{sec:zuverlaessigkeit}
Um die Zuverlässigkeit einer Software zu bestimmen, wird oftmals ein Wert verwendet,
der bestimmt, wie lang die Durchschnittszeit bis zum Ausfall des Systems ist.\cite[S. 9]{SoftwareQualitaet}
Ein Softwaresystem kann viele Ausfallgründe haben. Der wohl Einfachste ist eine zu hohe Auslastung des Systems.
Dieser Ausfallgrund wird in \Cref{sec:robustheit} genauer betrachtet. Desweiteren kann ein System durch falsche
Eingabewerte, oder ein unerwartetes Verhalten eines Nutzers, zum Ausfall gebracht werden. Mit automatisierten Langzeittests
sind diese zwei Ausfallgründe allerdings schwer zu berücksichtigen. So müsste der Entwickler bereits bei der Implementierung
der Tests über die möglichen Ausfallgründe Bescheid wissen. Um Störfalle zu verhindern, gilt es möglichst viele Szenarien mit
Tests abzudecken. Zur Beurteilung der Zuverlässigkeit der Software wird in der vorliegenden Arbeit die
Testabdeckung der einzelnen Komponenten des Systems betrachtet.

Um die fehlerfreie Zusammenarbeit der einzelnen Services sicherzustellen,
wurde der Fokus auf die Implementierung der Integrationstests gelegt.
Diese gehen gegen die Schnittstellen der Services. Bei dem "Resource Management Service"
sind alle Routen mit Tests abgedeckt. Für jede Route wurde die Rechteverwaltung,
die Authentisierung, die Validierung der Eingabe und Ausgabewerte sowie die Funktionalität der Route selbst getestet.
Der "Data Delivery Service" hingegen besitzt zum aktuellen Stand nur rudimentäre Tests der Hauptfunktionalitäten.
Hier wurden nicht wie bei dem "Resource Management Service" auf falsche Eingabewerte getestet. Außerdem fehlen die für
die Gesamtanwendung wichtigen End-To-End-Tests. Betrachtet man die progressive Webanwendung, wurden dort nur komplexe
Funktionalitäten mit Modultests abgedeckt.

\section{Verfügbarkeit}
\label{sec:verfuegbarkeit}
Zur Auswertung der Verfügbarkeit wird zuerst die Lastenverteilung analysiert und daraufhin
die Geschwindigkeit der Auslieferung über einen längeren Zeitraum getestet.

Um die Funktionalität der Lastenverteilung zu testen, wird in der Frontend-Anwendung
im Administrationsbereich die lokale Netzwerk-IP der aktuell verwendeten Instanz
angezeigt. Bei dem mehrfachen Neuladen der Anwendung, rotiert diese
durch alle Instanzen der Services. Der Lastverteiler funktioniert somit einwandfrei.
Überdies wird der Verkehr im Falle eines Ausfalls einer Instanz auf eine gesunde
Instanz verlegt.

Um einen besseren Überblick über die Verfügbarkeit der einzelnen
Services und derer Endpunkte zu bekommen, wird ein Lasttest über zehn Minuten mithilfe der Open Source Software
JMeter\footnote{https://jmeter.apache.org/} durchgeführt. Hier werden mehrere HTTPS- sowie
WSS-Anfrage hintereinander ausgeführt, um das anfängliche Verhalten eines Benutzers nachzuahmen.

\begin{figure}
    \begin{center}
    \includegraphics[scale=0.14]{img/abbildungen/Antwortzeitdiagramm3}
    \end{center}
    \caption{Antwortzeiten über Zeit (JMeter Lasttest)}
    \label{figure:antwortzeitenueberzeit}
\end{figure}

\begin{table}[h]
\begin{center}
\begin{tabular}{lrr}
Interaktion & Anfrage & Antwort \\
\hline
HTTPS: Landing-Page & \mytilde0,6KB & \mytilde2,9KB \\
HTTPS: CSS & \mytilde0,6KB & \mytilde152,2KB \\
HTTPS: JS Teil 1 & \mytilde0,6KB & \mytilde137,7KB \\
HTTPS: JS Teil 2 & \mytilde0,6KB & \mytilde722,9KB \\
HTTPS: Sign-In &  \mytilde0,7KB &  \mytilde0,9KB \\
HTTPS: Auflistung der Dashboards &   \mytilde0,6KB &  \mytilde2,9KB \\
WSS: Verbindung öffnen &   \mytilde0,6KB &  \mytilde0,1KB \\
WSS: Datenverkehr &   \mytilde0,2KB &  \mytilde23,3KB \\
\end{tabular}
\end{center}
\caption{Größe des Datenverkehrs}
\label{tab:groessedesdatenverkehrs}
\end{table}

Die Lasttestresultate der JMeter-Tests sind auf Abbildung \ref{figure:antwortzeitenueberzeit}
zu sehen. Das Diagramm zeigt die zur Beantwortung der jeweiligen Anfrage benötigte Zeit an.
Die Gesamtanwendung wurde für 10 Minuten getestet.
Der Test führt folgendes Szenario einmal in der Sekunde aus:
Als Erstes wird eine HTTPS-Anfrage an die \code{index.html} gesendet.
Zudem werden die nötigen CSS- und JS-Dateien geladen.
Daraufhin loggt sich der Benutzer mit seinen Benutzerdaten ein.
Sobald er eingeloggt ist, lädt der Benutzer über den "Resource Management Service"
eine Liste der \foreignlanguage{english}{Dashboards}. Als Nächstes wird eine WebSocket-Verbindung hergestellt
und eine Datenquelle abonniert. Nach Ankunft der ersten Daten der
Datenquelle, wird die WebSocket-Verbindung wieder geschlossen.

In Tabelle \ref{tab:groessedesdatenverkehrs} wird die Größe der versendeten und empfangenen 
Daten einer einzelnen Abfolge an Anfragen und deren Antworten aufgelistet.

In dem Schaubild der Abbildung \ref{figure:antwortzeitenueberzeit}
sind kurzzeitige Höhepunkte in der Antwortzeit zu erkennen. Da sich diese
in allen Services bemerkbar machen, ist davon auszugehen, dass dies
entweder durch einen Cron-Job des Docker Swarm Clusters ausgelöst wurde oder auf einen
Einbruch des Datenverkehrs der lokalen Internetverbindung des Testrechners zurückzuführen
ist.

Interessant ist, dass die Log-In-Anfrage trotz ihrer geringen Datentransfergröße verhältnismäßig
lange braucht. Bei der Anmeldung wird das Passwort gegen den Passwort-Hash in der Datenbank verglichen,
ein JWT generiert und als Cookie im Browser gesetzt. Eine Leistungssteigerung durch Verbesserung
des Log-In-Endpunktes ist denkbar. Die Landing-Page \code{index.html} sowie der Request-Body der
Anfrage an die Dashboard Ressource besitzten ungefähr die gleiche größe. Dennoch ist interessanterweise
der Node.js Server, der die \foreignlanguage{english}{Dashboards} ausliefert um ein vierfaches schneller. Dies könnte daran liegen,
dass die Anfrage gegen die Landing-Page als erstes stattfindet und somit der HTTPS-Handshake
mit einberechnet werden könnte.

Alles in allem gab es keine Fehlermeldungen bei den Anfragen, was darauf hinweist, dass das System
auch über längere Zeit eine hohe Verfügbarkeit aufweist.

\section{Robustheit}
\label{sec:robustheit}
Um die Robustheit der Gesamtanwendung zu testen, führt die Arbeit
einen speziellen Lasttests durch. Hierbei soll das Cluster auf maximale
Auslastung getestet werden. Da eine große Anzahl an Anfragen versendet werden müssen,
wird hierfür der Lasttestdienst Loader.io\footnote{https://loader.io/} verwendet.
Bei den Anfragen handelt es sich um HTTPS-Anfragen, die gegen
die \code{index.html} der Frontend-Anwendung gehen. Für den Test
wurden fünf Server zu einem Cluster zusammengefügt. Die einzelnen Services wurden
auf zehn Instanzen skaliert.

\begin{table}[h]
\begin{center}
\begin{tabular}{rrrrr}
Anfragen/Sek. & Fehlerrate & min. & max. & durchschn. \\
\hline
100 &  0\% & 86ms & 419ms & 92ms \\
250 &  0\% & 85ms & 549ms & 93ms \\
500 &  0\% & 85ms & 907ms & 95ms \\
1.000 &  0\% & 85ms & 8.431ms & 267ms \\
2.500 &  1,2\% & 90ms & 15.858ms & 1.974ms \\
5.000 &  8,9\% & 86ms & 19.994ms & 3.726ms \\
\end{tabular}
\end{center}
\caption{Antwortzeiten bei großer Auslastung}
\label{tab:resultatdeslasttestsmitloaderio}
\end{table}

In Tabelle \ref{tab:resultatdeslasttestsmitloaderio} sieht man die Resultate
der Lasttests mit Loader.io. Insgesamt wurden sechs Iterationen durchgeführt. Die Laufzeit der
Iterationen betrug eine Minute. Die Felder "min.", "max." und "durchschn." beziehen
sich auf die minimale, maximale und durchschnittliche
Antwortzeit, die die Server benötigen, um die
Anfragen zu verarbeiten. Für die Lasttests wurden die HTTPS-Anfragen,
die pro Sekunde abgesendet werden, von initial 100 auf bis zu 5.000 erhöht.

Ab ca. 2.500 Anfragen pro Sekunde fängt das Cluster an, Antworten auf die
Anfragen erst so spät zu versenden, dass die Antwort, die vom Client
erwartete Maximalzeit überschreitet.\footnote{Der "Timeout" für die ausgeführten Tests betrug 10 Sekunden.} Bei Betrachtung der maximalen Antwortzeit ist zu
erkennen, dass das Gesamtsystem bereits ab tausend Anfragen pro Sekunde
überlastet ist. Ein Nutzer sollte keine acht Sekunden auf eine Antwort warten
müssen. Bei fünfhundert abgehandelten Anfragen in der Sekunde bewegt sich die Durchschnittszeit
bei unter 100 Millisekunden.

Der Lasttest bestätigt, dass eine solide Robustheit der Gesamtanwendung gegeben ist.
Wie viele Benutzer ein solches Cluster mit fünf Servereinheiten
bedienen kann, ist schwer einzuschätzen. Zum einen verteilt sich die Hauptlast je nach
Benutzergruppe über mehrere Stunden am Tag, zum anderen sind die in der Arbeit ausgeführten
Lasttests nur schwer mit dem Verhalten echter Nutzer vergleichbar. Dies ist so,
da die Menge der zu übertragenden Daten je nach Benutzer variieren kann
und ohne echte Benutzerdaten schwer einzuschätzen ist.
